{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook created and tested by jecs89\n",
    "# source: https://www.geeksforgeeks.org/multiclass-classification-using-scikit-learn/\n",
    "\n",
    "# importing necessary libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the iris dataset\n",
    "iris = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X -> features, y -> label\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing X, y into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a DescisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree_model = DecisionTreeClassifier(max_depth = 2).fit(X_train, y_train)\n",
    "dtree_predictions = dtree_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a confusion matrix\n",
    "cm = confusion_matrix(y_test, dtree_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  1  0]\n",
      " [ 5 15  1]\n",
      " [ 0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test,dtree_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.94      0.83        16\n",
      "          1       0.94      0.71      0.81        21\n",
      "          2       0.89      1.00      0.94         8\n",
      "\n",
      "avg / total       0.86      0.84      0.84        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,dtree_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image  \n",
    "from sklearn import tree\n",
    "\n",
    "# Create DOT data\n",
    "dotfile = open(\"dtree2.dot\", 'w')\n",
    "dot_data = tree.export_graphviz(dtree_model, out_file=dotfile, \n",
    "                                feature_names=iris.feature_names,  \n",
    "                                class_names=iris.target_names)\n",
    "dotfile.close()\n",
    "#http://webgraphviz.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a linear SVM classifier\n",
    "from sklearn.svm import SVC\n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, y_train)\n",
    "svm_predictions = svm_model_linear.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model accuracy for X_test  \n",
    "accuracy = svm_model_linear.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a confusion matrix\n",
    "cm = confusion_matrix(y_test, svm_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 0 20  1]\n",
      " [ 0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        16\n",
      "          1       1.00      0.95      0.98        21\n",
      "          2       0.89      1.00      0.94         8\n",
      "\n",
      "avg / total       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a KNN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "# accuracy on X_test\n",
    "accuracy = knn.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a confusion matrix\n",
    "knn_predictions = knn.predict(X_test) \n",
    "cm = confusion_matrix(y_test, knn_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  1  1]\n",
      " [ 0 16  5]\n",
      " [ 1  2  5]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,knn_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.88      0.90        16\n",
      "          1       0.84      0.76      0.80        21\n",
      "          2       0.45      0.62      0.53         8\n",
      "\n",
      "avg / total       0.81      0.78      0.79        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,knn_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a Naive Bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB().fit(X_train, y_train)\n",
    "gnb_predictions = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# accuracy on X_test\n",
    "accuracy = gnb.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a confusion matrix\n",
    "cm = confusion_matrix(y_test, gnb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 2 18  1]\n",
      " [ 0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,gnb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        16\n",
      "          1       1.00      0.86      0.92        21\n",
      "          2       0.89      1.00      0.94         8\n",
      "\n",
      "avg / total       0.94      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,gnb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
